{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Forecasting Brent Oil Prices\n",
    "\n",
    "In this notebook, we will develop a forecasting model for Brent oil prices. This involves:\n",
    "1. Checking for stationarity in the time series data.\n",
    "2. Preparing the data for model training and testing.\n",
    "3. Building a time series forecasting model, starting with ARIMA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import os\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import warnings\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "# from pmdarima import auto_arima\n",
    "os.chdir(r'c:\\users\\ermias.tadesse\\10x\\Oil-Price-Insights')  # Set the working directory to the project root\n",
    "# Load the Brent Oil Prices dataset\n",
    "file_path = 'Data/Raw/BrentOilPrices.csv'\n",
    "\n",
    "# Load the Brent Oil Prices dataset\n",
    "# data = pd.read_csv('../Data/BrentOilPrice.csv', index_col='Date', parse_dates=True)\n",
    "data = pd.read_csv(file_path)\n",
    "data = data[['Price']].dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADF Statistic: -1.993856011392467\n",
      "p-value: 0.2892735048934032\n",
      "The data is likely non-stationary. Consider differencing for stationary models.\n"
     ]
    }
   ],
   "source": [
    "# Perform the ADF test for stationarity\n",
    "result = adfuller(data['Price'])\n",
    "print('ADF Statistic:', result[0])\n",
    "print('p-value:', result[1])\n",
    "\n",
    "# Interpretation of the result\n",
    "if result[1] > 0.05:\n",
    "    print(\"The data is likely non-stationary. Consider differencing for stationary models.\")\n",
    "else:\n",
    "    print(\"The data is likely stationary.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data points: 7208, Testing data points: 1803\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test sets (e.g., 80% train, 20% test)\n",
    "train_size = int(len(data) * 0.8)\n",
    "train, test = data[:train_size], data[train_size:]\n",
    "\n",
    "print(f\"Training data points: {len(train)}, Testing data points: {len(test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Building the ARIMA Model\n",
    "\n",
    "We will build an ARIMA model for forecasting Brent oil prices. The steps include:\n",
    "1. Using auto_arima to find the best (p, d, q) parameters.\n",
    "2. Fitting the ARIMA model with the training data.\n",
    "3. Forecasting and evaluating the model performance on the test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the range of p, d, q values to try\n",
    "p_values = range(0, 4)\n",
    "d_values = range(0, 2)\n",
    "q_values = range(0, 4)\n",
    "\n",
    "# Grid search to find the best parameters\n",
    "best_aic = float(\"inf\")\n",
    "best_order = None\n",
    "best_model = None\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # Suppress warnings for cleaner output\n",
    "\n",
    "for p in p_values:\n",
    "    for d in d_values:\n",
    "        for q in q_values:\n",
    "            try:\n",
    "                model = ARIMA(train, order=(p, d, q))\n",
    "                model_fit = model.fit()\n",
    "                aic = model_fit.aic\n",
    "                if aic < best_aic:\n",
    "                    best_aic = aic\n",
    "                    best_order = (p, d, q)\n",
    "                    best_model = model_fit\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "print(f\"Best ARIMA order: {best_order} with AIC: {best_aic}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best order found from the grid search\n",
    "p, d, q = best_order\n",
    "arima_model = ARIMA(train, order=(p, d, q))\n",
    "arima_model_fit = arima_model.fit()\n",
    "\n",
    "# Forecast the test set\n",
    "forecast = arima_model_fit.forecast(steps=len(test))\n",
    "forecast.index = test.index\n",
    "\n",
    "# Plotting the forecast against actual prices\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train, label='Training Data')\n",
    "plt.plot(test, label='Actual Prices')\n",
    "plt.plot(forecast, label='Forecasted Prices', color='red')\n",
    "plt.title(\"ARIMA Model Forecast vs Actual Prices\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model's performance\n",
    "mse = mean_squared_error(test, forecast)\n",
    "mae = mean_absolute_error(test, forecast)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"Mean Absolute Error: {mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Residual Diagnostics and Baseline Comparison\n",
    "\n",
    "We will:\n",
    "1. Analyze residuals to ensure that they are randomly distributed (indicating a good model fit).\n",
    "2. Compare our ARIMA model with a simple baseline model to see if it adds value over a naive forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot residuals\n",
    "residuals = arima_model_fit.resid\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot residuals over time\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(residuals)\n",
    "plt.title(\"Residuals Over Time\")\n",
    "\n",
    "# Plot residuals histogram\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(residuals, kde=True)\n",
    "plt.title(\"Residuals Distribution\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Conduct normality test on residuals\n",
    "k2, p = stats.normaltest(residuals)\n",
    "print(f\"Normality test p-value: {p}\")\n",
    "\n",
    "if p > 0.05:\n",
    "    print(\"Residuals appear to be normally distributed.\")\n",
    "else:\n",
    "    print(\"Residuals may not be normally distributed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive forecast: Use the last value of the training set as the forecast for all test points\n",
    "naive_forecast = [train.iloc[-1]] * len(test)\n",
    "\n",
    "# Plot naive forecast against actual prices\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train, label='Training Data')\n",
    "plt.plot(test, label='Actual Prices')\n",
    "plt.plot(test.index, naive_forecast, label='Naive Forecast', color='green')\n",
    "plt.plot(forecast, label='ARIMA Forecast', color='red')\n",
    "plt.title(\"Naive Forecast vs ARIMA Forecast vs Actual Prices\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Calculate performance metrics for naive forecast\n",
    "naive_mse = mean_squared_error(test, naive_forecast)\n",
    "naive_mae = mean_absolute_error(test, naive_forecast)\n",
    "print(f\"Naive Forecast - Mean Squared Error: {naive_mse}\")\n",
    "print(f\"Naive Forecast - Mean Absolute Error: {naive_mae}\")\n",
    "\n",
    "# Compare ARIMA and Naive Model\n",
    "print(\"\\nComparison with ARIMA Model:\")\n",
    "print(f\"ARIMA MSE: {mse}, Naive MSE: {naive_mse}\")\n",
    "print(f\"ARIMA MAE: {mae}, Naive MAE: {naive_mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Building an ETS Model (Holt-Winters Exponential Smoothing)\n",
    "\n",
    "In this step, we will apply an ETS model using Holt-Winters Exponential Smoothing. This model is useful for time series with trend and seasonality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fit the ETS model with trend and seasonality\n",
    "ets_model = ExponentialSmoothing(train, trend='add', seasonal='add', seasonal_periods=12)\n",
    "ets_model_fit = ets_model.fit()\n",
    "\n",
    "# Forecast the test set\n",
    "ets_forecast = ets_model_fit.forecast(steps=len(test))\n",
    "ets_forecast.index = test.index\n",
    "\n",
    "# Plot ETS forecast against actual prices\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train, label='Training Data')\n",
    "plt.plot(test, label='Actual Prices')\n",
    "plt.plot(ets_forecast, label='ETS Forecast', color='purple')\n",
    "plt.title(\"ETS Model Forecast vs Actual Prices\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate performance metrics for ETS model\n",
    "ets_mse = mean_squared_error(test, ets_forecast)\n",
    "ets_mae = mean_absolute_error(test, ets_forecast)\n",
    "\n",
    "print(f\"ETS Model - Mean Squared Error: {ets_mse}\")\n",
    "print(f\"ETS Model - Mean Absolute Error: {ets_mae}\")\n",
    "\n",
    "# Compare ETS with ARIMA and Naive Forecast\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(f\"ARIMA MSE: {mse}, ETS MSE: {ets_mse}, Naive MSE: {naive_mse}\")\n",
    "print(f\"ARIMA MAE: {mae}, ETS MAE: {ets_mae}, Naive MAE: {naive_mae}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Building an LSTM Model for Time Series Forecasting\n",
    "\n",
    "In this step, we will build and train an LSTM model to forecast Brent oil prices. We’ll preprocess the data, set up the LSTM model, and evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data to range [0, 1]\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# Prepare training and test sets\n",
    "train_scaled = scaled_data[:train_size]\n",
    "test_scaled = scaled_data[train_size:]\n",
    "\n",
    "# Convert series to supervised learning format\n",
    "def create_sequences(data, sequence_length=30):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        X.append(data[i:i+sequence_length, 0])\n",
    "        y.append(data[i+sequence_length, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "sequence_length = 30  # Number of past days to consider\n",
    "X_train, y_train = create_sequences(train_scaled, sequence_length)\n",
    "X_test, y_test = create_sequences(test_scaled, sequence_length)\n",
    "\n",
    "# Reshape input data to 3D [samples, timesteps, features] for LSTM\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data\n",
    "predictions = model.predict(X_test)\n",
    "predictions = scaler.inverse_transform(predictions)  # Rescale back to original values\n",
    "y_test_actual = scaler.inverse_transform(y_test.reshape(-1, 1))  # Rescale y_test for comparison\n",
    "\n",
    "# Plot the forecast\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(test.index[sequence_length:], y_test_actual, label='Actual Prices')\n",
    "plt.plot(test.index[sequence_length:], predictions, label='LSTM Forecast', color='orange')\n",
    "plt.title(\"LSTM Model Forecast vs Actual Prices\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate performance metrics for LSTM\n",
    "lstm_mse = mean_squared_error(y_test_actual, predictions)\n",
    "lstm_mae = mean_absolute_error(y_test_actual, predictions)\n",
    "\n",
    "print(f\"LSTM Model - Mean Squared Error: {lstm_mse}\")\n",
    "print(f\"LSTM Model - Mean Absolute Error: {lstm_mae}\")\n",
    "\n",
    "# Compare LSTM with other models\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(f\"ARIMA MSE: {mse}, ETS MSE: {ets_mse}, LSTM MSE: {lstm_mse}\")\n",
    "print(f\"ARIMA MAE: {mae}, ETS MAE: {ets_mae}, LSTM MAE: {lstm_mae}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
